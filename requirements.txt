The MSK module integrates multi-scale encoder features through an efficient spatial-focused fusion process. As illustrated in Fig. 3, it takes the channel-wise concatenation of encoder features (F₁, F₂, F₃) as input. A 1×1 convolution first compresses the features to C/4 channels. In this compressed space, three standard convolutions (3×3, 5×5, 7×7) are applied in parallel to extract multi-scale spatial patterns, and their outputs are summed together. Although these are regular convolutions, the overall cost remains low because all operations are performed on the compressed feature map with only C/4 channels. For spatial attention, average and max pooling are applied along the channel axis, and their results are concatenated and processed by a 7×7 convolution with sigmoid activation, producing an attention map that modulates the fused features via multiplication. A final 1×1 convolution restores the channel dimension.

This design improves efficiency compared to the baseline MSAA by operating in a compressed feature space and using only spatial attention. A standard channel attention module requires C'²/2 parameters, while the spatial attention here uses only 98 parameters (a 7×7 conv with 2 input channels). When C'=32, this reduces attention-related parameters from 512 to 98, achieving over 80% reduction.

