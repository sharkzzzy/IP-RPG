The PMC module is inspired by Learnable Deformable Convolution (LDC) [8], but operates in the parameter domain rather than the spatial domain. This design choice is motivated by a key observation: standard convolutions exhibit a center-dominance tendency, where center weights consistently receive larger magnitudes after training. This occurs partly because the kernel center always corresponds to a well-aligned sampling position across spatial locations, and is repeatedly reinforced by overlapping receptive fields, leading to more stable gradient signals and larger cumulative updates during optimization. Although a sufficiently expressive network could, in principle, learn non-center-dominant kernels from data, standard training does not explicitly encourage such behavior; consequently, gradient-based optimization tends to converge to center-reliant solutions that minimize training loss but remain suboptimal for fine-detail extraction. By shifting the deformation from the spatial to the parameter domain, PMC eliminates the complex coordinate offset and interpolation computations required in traditional LDC, while introducing a lightweight, learnable inhibitory prior to counteract center-dominance.
The core mechanism works as follows: a dynamic mask, correlated with the convolutional kernel weights, adaptively modulates the convolution weights and suppresses the intensity at the kernel's center. This suppression compels the network to gather information from neighboring positions, enhancing sensitivity to edges and fine texturesâ€”precisely the local details this path aims to capture.
