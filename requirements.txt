The proposed DP-UNet is an improved architecture over CM-UNet, designed to enhance segmentation accuracy and optimize computational efficiency through structural innovations. It achieves these goals by replacing the original MSAA with the MSK module to eliminate redundant computations and by introducing the DVSS block in place of the single-path CSMamba block, thereby decoupling global context modeling from local detail refinement. As illustrated in Fig. 1(a), the network consists of three main components: a ResNet-18-based [3] encoder for multi-level feature extraction, MSK modules for multi-scale feature fusion, and a DVSS-based decoder for progressive upsampling and refinement.
Given an input image I\in R^{H\times W\times\mathbb{3}}, the encoder produces four-level features \{F_1,F_2,F_3,F_4\} at 1/4, 1/8, 1/16, and 1/32 of the original resolution. Three MSK modules enhance \{F_1,F_2,F_3\} through cross-scale fusion to obtain enriched skip features \{F_1^\prime,F_2^\prime,F_3^\prime\} (Section II-B), while F_4 is preserved. The decoder reconstructs the segmentation map through four stages: stage 0 processes F_4, and stages 1-3 progressively fuse with \{F_3^\prime,F_2^\prime,F_1^\prime\} via skip connections and DVSS blocks (Section II-A). The final prediction P is produced by a 1\ \times1 convolution head and bilinearly upsampled to the original resolution. Formally:
{F1,F2,F3,F4}=EncI, Fi'=MSKiF1,F2,F3
D0=DVSS0F4,Di=DVSSiProjUpDi-1,F4-i'
P=HeadD3,L=JP,Y+λi=13JPi,Y
where \mathrm{Enc}\left(\cdot\right) denotes the encoder, \mathrm{MS}\mathrm{K}_\mathrm{i} fuses multi-scale features with the other two scales resized to the target resolution, \mathrm{Proj}\left(\cdot\right) is a point-wise projection for channel reduction, and \mathrm{Up}\left(\cdot\right) denotes bilinear upsampling. P_i are auxiliary predictions from decoder stages 1-3, J\left(\cdot,\cdot\right) is a joint loss combining cross-entropy and Dice loss, and\ \lambda=0.4 is the weight for auxiliary losses.

A. Main decoder (DVSS)
The decoder consists of four stages: stage 0 refines F₄, while stages 1–3 fuse upsampled features with skip features F_3^\prime,F_2^\prime,F_1^\prime via concatenation, 1\times1 projection, and DVSS blocks. Each DVSS decouples global and local processing—the local path applies ECA for channel recalibration followed by PMC-modulated convolution\ (W_{eff}), then both paths are fused by APFG. Auxiliary heads at stages 1–3 provide deep supervision. 
To motivate our design, we revisit the baseline CSMamba decoder. As shown in Fig. 1(b), its core SS2D module captures global context via four-directional 2D-SSM scanning [4] and employs internal channel/spatial attention gates. The SS2D module internally integrates both channel and spatial attention mechanisms as gates to enhance its feature selection capabilities. We posit that global semantic context modeling and local spatial detail refinement are distinct tasks, yet they share the same underlying feature foundation. Processing them sequentially within the single-path architecture of the original decoder may prevent either task from achieving optimal performance. The DVSS adopts a "shared base, separate enhancement" design philosophy. Its core idea is to have global and local processing share the same underlying feature source before undergoing task-specific optimization.
The structure of the DVSS is shown in Fig. 1(c). The input feature X\in\mathbb{R}^{\left(B\times H\times W\times C\right)} is first normalized and processed by the SS2D module to produce a shared foundational feature F_s. This feature serves both paths: the global path retains F_s directly, while the local detail path processes it as follows. It undergoes channel recalibration through an Efficient Channel Attention (ECA) [5] module, which models cross-channel dependencies via a lightweight 1D convolution. This recalibration helps the subsequent PMC focus on informative channels. The recalibrated feature is enhanced via a residual connection before being fed into the PMC module.
The PMC module is inspired by Learnable Deformable Convolution (LDC) [6], but operates in the parameter domain rather than the spatial domain. This design choice is motivated by a key observation: standard convolutions exhibit a center-dominance tendency, where center weights consistently receive larger magnitudes after training. This occurs partly because the kernel center always corresponds to a well-aligned sampling position across spatial locations, and is repeatedly reinforced by overlapping receptive fields, leading to more stable gradient signals and larger cumulative updates during  
